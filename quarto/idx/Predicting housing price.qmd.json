{"title":"project6323.","markdown":{"headingText":"project6323.","containsRefs":false,"markdown":"## xiaoyan Zhang\n## purpose\n#######################################################\n## The project is to build the model to forcast the ###\n## house price, useing house data from redfin and    ##\n## Dallas HPI, linear regression, random forest, and ##\n## gradient boosting tree are used and compared for  ##\n## this project.                                     ##\n#######################################################\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(lubridate)\ninstall.packages('caret')\ninstall.packages('randomForest')\nlibrary(caret)\ninstall.packages('zoo')\nlibrary(zoo)\nlibrary(randomForest)\nlibrary(rsample)\ninstall.packages('gbm')\nlibrary(gbm)\n\n################ input data  #############\n#read house data\nhouse_data<- house_data\n\n# read HPI data\nhpi<- Dallas_HPI\n\n# transformation\n# convert house data sold_month to date\n#library(lubridate)\n\nhouse_data$SOLD_MONTH<-mdy(house_data$SOLD_MONTH)\nhouse_data$base_month<- floor_date(house_data$SOLD_MONTH, unit = \"month\") - months(1)\n\n\nhouse_data<- house_data[house_data$SOLD_MONTH< as.Date(\"2023-01-01\"),]\n\nhouse_data2<-house_data[house_data$BEDS ==1, ]\n#drop beds outlier\nhouse_data<- house_data[-2098,]\n\n# convert HPI date string  to date\nhpi$DATE<-mdy(hpi$DATE)\n\n#create lag hpi\n#library(dplyr)\nhpi<- hpi %>%\n  mutate(hpi_lag1 = lag(HPI)) %>%\n  mutate(hpi_lag3 = lag(HPI, n=3)) %>%\n  mutate(hpi_lag6= lag(HPI, n=6))\n\n#create the hpi percentage change\nhpi$hpi_1m_pct <- (hpi$HPI-hpi$hpi_lag1)/hpi$hpi_lag1\nhpi$hpi_3m_pct <- (hpi$HPI-hpi$hpi_lag3)/hpi$hpi_lag3\nhpi$hpi_6m_pct <- (hpi$HPI-hpi$hpi_lag6)/hpi$hpi_lag6\n\n#join house table and hpi table by date\nhouse_df<- merge(house_data, hpi,by.x=\"base_month\", by.y=\"DATE\", all.x= TRUE, all.y=FALSE)\n\n# do histogram of price, squarefeet, lotsize\nhist(house_df$PRICE)\nhist(house_df$SQUAREFEET)\nhist(house_df$LOTSIZE)\nhist(house_df$BEDS)\n\n## create new variables of house data\n# extract sold year from house data\nhouse_df$sold_year <- year(as.Date(house_df$SOLD_MONTH))\nprint(house_df$sold_year)\n\n#  house age \nhouse_df$houseage <- house_df$sold_year- house_df$YEARBUILT\nhouse_df$houseage\n\n#total beds and bath\nhouse_df$total_beds_baths <- house_df$BEDS + house_df$BATHS\n\n#baths and beds ratio\nhouse_df$bath_bed_ratio <- ifelse(house_df$BEDS==0,NA, house_df$BATHS/house_df$BEDS)\n\n#living squarefeet and beds ratio\nhouse_df$sqrt_beds <- ifelse(house_df$BEDS==0, NA, house_df$SQUAREFEET/house_df$BEDS)\n\n############################ data clean #################\n# check price\nquantile(na.omit((house_df$PRICE)),c(0,0.01,0.1,0.25,0.5,0.75,0.9,0.95,0.99,1))\n# check beds\nquantile(na.omit((house_df$BEDS)),c(0,0.01,0.1,0.25,0.5,0.75,0.9,0.95,0.99,1))\n#check baths\nquantile(na.omit((house_df$BATHS)),c(0,0.01,0.1,0.25,0.5,0.75,0.9,0.95,0.99,1))\n#check lotsize \nquantile(na.omit((house_df$LOTSIZE)),c(0,0.01,0.1,0.25,0.5,0.75,0.9,0.95,0.99,1))\n#check living squarefeet\nquantile(na.omit((house_df$SQUAREFEET)),c(0,0.01,0.1,0.25,0.5,0.75,0.9,0.95,0.99,1))\n\n# impute the lotsize outlier to median\nmed_lot<- median(house_df$LOTSIZE, na.rm = TRUE )\nhouse_df$LOTSIZE_imputed <- ifelse(is.na(house_df$LOTSIZE)|house_df$LOTSIZE > 30000|house_df$LOTSIZE< 2000, med_lot,\n                                   house_df$LOTSIZE)\nhouse_df$LOTSIZE_imputed_ind<-ifelse(is.na(house_df$LOTSIZE)|house_df$LOTSIZE > 30000|house_df$LOTSIZE< 2000, 1,0)\n\n\n#check  missing value \nsum(is.na(house_df$PRICE))\nsum(is.na(house_df$LOTSIZE))\nsum(is.na(house_df$BEDS))\nsum(is.na(house_df$BATHS))\nsum(is.na(house_df$SQUAREFEET))\n\n#rows missing\n#rows_missing <- setdiff(1:nrow(house_df[\"PRICE\"]),which(complete.cases((house_df$PRICE))))\n\n# drop rows of missing price\nhouse_df <- house_df[complete.cases(house_df$PRICE), ]\n\n## variable transformation \n#log transformation for house price, lotsize, squarefeet\n\nhist(house_df$PRICE)\nhist(log(house_df$PRICE))\nhouse_df$log_price <- log(house_df$PRICE)\n\nhist(house_df$SQUAREFEET)\nhist(log(house_df$SQUAREFEET))\n# log sqrt is skewed to the left, original is better\n\nhist(house_df$LOTSIZE_imputed)\nhist(log(house_df$LOTSIZE_imputed))\nhouse_df$log_lotsize <- log(house_df$LOTSIZE_imputed)\nhist(house_df$BEDS)\nhist(house_df$BATHS)\n\n############################# data analysis ####################\n## cross table\n# frequency of zip code\nzip_freq<- table(house_df$ZIP)\nzip_freq\n#frequency of house age\nhouseage_freq <- table(house_df$houseage)\nhouseage_freq\n\n# frequency of number of beds\nbeds_freq<- table(house_df$BEDS)\nbeds_freq\n# frequency of number of baths\nbaths_freq<- table(house_df$BATHS)\nbaths_freq\n#cross table by zip *number of beds\nZIP_BEDS<- xtabs(~ ZIP + BEDS, data= house_df)\nZIP_BEDS\n#cross table by zip *number of baths\nZIP_BATHS<- xtabs(~ ZIP + BATHS, data = house_df)\nZIP_BATHS\n#cross table by number of beds * number of baths\nbeds_baths<- xtabs(~ BEDS + BATHS, data = house_df )\nbeds_baths\n\n#mean price by month\nprice_aver_month<-aggregate(PRICE~ SOLD_MONTH, data= house_df, mean)\nprice_aver_month\nplot(price_aver_month$SOLD_MONTH,price_aver_month$PRICE, xlab=\"SOLD_MONTH\", ylab =\"PRICE\",\n     main=\"Mean Price by Month\", type= \"l\",xaxt = \"n\")  # xaxt = \"n\" removes default x-axis labels\naxis(side = 1, at =  price_aver_month$SOLD_MONTH, labels = price_aver_month$SOLD_MONTH) \n\n#mean price by number of beds\nprice_aver_beds<-aggregate(PRICE ~ BEDS , data= house_df, mean)\nprice_aver_beds\nplot(price_aver_beds$BEDS,price_aver_beds$PRICE, xlab=\"BEDS\", ylab =\"PRICE\",\n     main=\"Mean Price by Beds\", type= \"l\",xaxt = \"n\")  # xaxt = \"n\" removes default x-axis labels\naxis(side = 1, at =  price_aver_beds$BEDS, labels = price_aver_beds$BEDS) \n\n#mean price by number of baths\nprice_aver_BATHS<-aggregate(PRICE ~ BATHS , data= house_df, mean)\nprice_aver_BATHS\nplot(price_aver_BATHS$BATHS,price_aver_BATHS$PRICE, xlab=\"BATHS\", ylab =\"PRICE\",\n     main=\"Mean Price by Baths\", type= \"l\",xaxt = \"n\")  # xaxt = \"n\" removes default x-axis labels\naxis(side = 1, at =  price_aver_BATHS$BATHS, labels = price_aver_BATHS$BATHS)\n#mean price by houseage\nprice_aver_houseage<-aggregate(PRICE ~ houseage , data= house_df, mean)\nprice_aver_houseage\nplot(price_aver_houseage$houseage,price_aver_houseage$PRICE, xlab=\"houseage\", ylab =\"PRICE\",\n     main=\"Mean Price by houseage\", type= \"l\",xaxt = \"n\")  # xaxt = \"n\" removes default x-axis labels\naxis(side = 1, at =  price_aver_houseage$houseage, labels = price_aver_houseage$houseage)\n\n# scatter plot of price by living square feet\n\np <- ggplot(house_df,aes(x=SQUAREFEET, y=PRICE ))+geom_point()+ geom_smooth(method=\"lm\", se = FALSE)\nprint(p)\n\n#median price by month\nprice_med_month <- aggregate(PRICE ~ SOLD_MONTH, data=house_df, median)\nplot(price_med_month$SOLD_MONTH, price_med_month$PRICE, xlab=\"SOLD_MONTH\", ylab =\"PRICE\",\n     main=\"Median Price by Month\", type= \"l\",xaxt = \"n\")  # xaxt = \"n\" removes default x-axis labels\naxis(side = 1, at =  price_med_month$SOLD_MONTH, labels = price_med_month$SOLD_MONTH) \n\n#median price by number of beds\nprice_med_beds <- aggregate(PRICE ~ BEDS, data=house_df, median)\nplot(price_med_beds$BEDS, price_med_beds$PRICE, xlab=\"BEDS\", ylab =\"PRICE\",\n     main=\"Median Price by Beds\", type= \"l\",xaxt = \"n\")  # xaxt = \"n\" removes default x-axis labels\naxis(side = 1, at =  price_med_beds$BEDS, labels = price_med_beds$BEDS) \n\n#median price by baths\nprice_med_baths <- aggregate(PRICE ~ BATHS, data=house_df, median)\nplot(price_med_baths$BATHS, price_med_baths$PRICE, xlab=\"BATHS\", ylab =\"PRICE\",\n     main=\"Median Price by Baths\", type= \"l\",xaxt = \"n\")  # xaxt = \"n\" removes default x-axis labels\naxis(side = 1, at =  price_med_baths$BATHS, labels = price_med_baths$BATHS) \n\n#median price by houseage\nprice_med_houseage <- aggregate(PRICE ~ houseage, data=house_df, median)\nplot(price_med_houseage$houseage, price_med_houseage$PRICE, xlab=\"houseage\", ylab =\"PRICE\",\n     main=\"Median Price by houseage\", type= \"l\",xaxt = \"n\")  # xaxt = \"n\" removes default x-axis labels\naxis(side = 1, at =  price_med_houseage$houseage, labels = price_med_houseage$houseage) \n\n# create new variable age group \n\n#library(dplyr)\nhouse_df <- house_df %>%\n  mutate(age_group = cut(houseage, breaks = c(-0.5,5,10,15,20,25, Inf), labels = c(\"0-5\", \"6-10\", \"11-15\",\"16-20\",\"21-25\",\"25+\"))) \nhouse_df\n#mean price by age group\nprice_aver_age_group<-aggregate(PRICE ~ age_group , data= house_df, mean)\nprice_aver_age_group\nplot(price_aver_age_group$age_group,price_aver_age_group$PRICE, xlab=\"age_group\", ylab =\"PRICE\",\n     main=\"Mean Price by age_group \", type= \"p\",xaxt = \"n\")  # xaxt = \"n\" removes default x-axis labels\naxis(side = 1, at =  price_aver_age_group$age_group, labels = price_aver_age_group$age_group)\n\n#median price by age group\nprice_med_age_group<-aggregate(PRICE ~ age_group , data= house_df, median)\nprice_med_age_group\nplot(price_med_age_group$age_group,price_med_age_group$PRICE, xlab=\"age_group\", ylab =\"PRICE\",\n     main=\"Median Price by age_group \", type= \"p\",xaxt = \"n\")  # xaxt = \"n\" removes default x-axis labels\naxis(side = 1, at =  price_med_age_group$age_group, labels = price_med_age_group$age_group)\n\n\n# create new variable month from sold month \nhouse_df$month_ind<- as.factor(month(house_df$SOLD_MONTH))\n\n# keep list\nkeep_list<-  c(\"BEDS\",\"BATHS\",\"SQUAREFEET\",\"HPI\",\"hpi_lag1\",\"hpi_lag3\",\"hpi_lag6\",\"hpi_1m_pct\", \n               \"hpi_3m_pct\",\"hpi_6m_pct\",\"houseage\",\"total_beds_baths\",\"bath_bed_ratio\",\"sqrt_beds\",\"LOTSIZE_imputed_ind\",\n               \"log_price\",\"log_lotsize\", \"month_ind\")\nhouse_df<-house_df[,keep_list]\n\n\n################## split the data ##################################\n#split the data to training data and testing data\n\nlibrary(rsample)\nset.seed(123)\ninitial_split_df<- initial_split(house_df, prop = 0.7)\ntrain_data<- training(initial_split_df)\ntest_data<- testing(initial_split_df)\n\n########################### build 3 models ##################################\n## build linear regression model\n\n\nreg_model <- lm(log_price  ~ \n                  #BEDS + \n                  BATHS+\n                  SQUAREFEET+\n                  #HPI+\n                  # hpi_lag1+\n                  hpi_lag3+\n                  #hpi_lag6+\n                  # hpi_1m_pct+\n                  hpi_3m_pct+\n                  # hpi_6m_pct+\n                  houseage+\n                  #total_beds_baths,\n                  #bath_bed_ratio+\n                  #sqrt_beds+\n                  LOTSIZE_imputed_ind+\n                  log_lotsize,\n                #month_ind, \n                data = train_data )\nsummary(reg_model)\n# predict linear regression model  on testing data\nprediction <- predict(reg_model, newdata = test_data)\nplot(prediction, test_data$log_price)\nmse_pred<- mean((test_data$log_price - prediction)^2)\nsqrt(mse_pred)\n\n# do prediction with lasso\nlibrary(glmnet)\ngrid <- 10^seq(10, -5, length = 1000)  # lambda search grid\n\nx_train<- select(train_data, -log_price)\nmonth_df <- data.frame(model.matrix(~ month_ind - 1, data= x_train))\n# add column name to month_ind\ncolnames(month_df)<- paste0(\"month_\", levels(x_train$month_ind))\nx_train2<- cbind(x_train,month_df )\nx_train2<- select(x_train2, - month_ind)\n# change testing data as training data\nx_test<- select(test_data, -log_price)\nmonth_df_test <- data.frame(model.matrix(~ month_ind - 1, data= x_test))\n# add column name to minth_ind\ncolnames(month_df)<- paste0(\"month_\", levels(x_test$month_ind))\nx_test2<- cbind(x_test,month_df_test )\nx_test2<- select(x_test2, - month_ind)\n\n\nlasso_model <- glmnet(x_train2, train_data[ ,\"log_price\"] , alpha = 1, lambda= grid )\n# to find the best lambda\nset.seed(1)\ncv.out <- cv.glmnet(as.matrix(x_train2), train_data[ ,\"log_price\"], alpha = 1)\nplot(cv.out)\nbestlam <- cv.out$lambda.min\nlasso.pred <- predict(lasso_model, s = bestlam, newx = as.matrix(x_test2))\nMSE.linreg = mean((lasso.pred - test_data$log_price)^2)     # lowest MSE\n\n\n## build random forest model\n\n#check missing value of train_data\ntrain.rf <- na.omit(train_data)\ncolSums(is.na(train_data_rf))\ncolSums(is.na(train_data))\n# check missing value of test_data\ntest.rf <- na.omit(test_data)\ncolSums(is.na(test_data_rf))\ncolSums(is.na(test_data))\n\n# tune random forest \nrf.tuning<- tuneRF(select(train.rf, -log_price), train.rf$log_price, \n                   ntreeTry=500, stepFactor= 1.5,\n                   improve = 0, trace= TRUE, plot=TRUE)\nmtry = 7  # see rf.tuning ... low OOB for 7\n\nset.seed(1)\n\nrf <- randomForest(log_price ~ ., data=train.rf, importance=TRUE, proximity=TRUE, ntree=500,\n                   mtry=mtry)\nrf.plot <- plot(rf, log=\"y\", main=\"OOB Error Rate vs. Number of Trees\")\nrf.plot\n\nvar_importance <- rf$importance\nvar_importance_sorted <- var_importance[order(var_importance[,1], decreasing = FALSE),]\nbarplot(var_importance_sorted[,1],\n        names.arg = rownames(var_importance), \n        xlab = \"Score\",\n        main = \"Variable Importance\",\n        horiz = TRUE,las=1,)\npar(mar = c(3, 15, 2, 4))\n\ntrain.pred <- train.rf\ntrain.pred$PRED <- predict(rf, train.rf)\n\ntest.rf.pred <- test.rf\ntest.rf.pred$PRED <- predict(rf, test.rf)\n\nrf.pred.plot <- plot(test.rf.pred$PRED, test.rf$log_price)\nabline(0, 1)\nrf.pred.plot\n\nMSE.rf = mean((test.rf.pred$PRED - test.rf.pred$log_price)^2)\n\n\n# Prediction\ntest_pred <- predict(bag_train_data, newdata = test_data_rf)\nplot(test_pred, test_data_rf$log_price)\nabline(0, 1)\nmean((test_pred - test_data_rf$log_price)^2)\n\n\n## build gradient boosting tree model \nlibrary(gbm)\n# drop  similar variables based on importance\ntrain_data2<-subset(train_data, select = -c(hpi_lag3,hpi_1m_pct,hpi_6m_pct,hpi_lag1, HPI))\n\n\nset.seed(1)\nn_trees <- 100\nlearning_rate <- 0.1\nmax_depth <- 10\npred_train<-  matrix(0, nrow = nrow(train_data2), ncol = n_trees)\n\npred_test <- matrix(0, nrow = nrow(test_data), ncol = n_trees)\n#use for loop to make predict\nfor (i in 1:n_trees) {\n  model <- gbm(log_price ~ ., data = train_data2, n.trees = i, \n               interaction.depth = max_depth, shrinkage = learning_rate,\n               distribution = \"gaussian\")\n  pred_train[, i] <- predict(model, newdata = train_data2, n.trees = i)\n  pred_test[, i] <- predict(model, newdata = test_data, n.trees = i)\n}\n\n\n#combine the prediction\nerror_list_train <- apply((pred_train-train_data2$log_price)^2, 2, mean)\n\nerror_list_test <- apply((pred_test-test_data$log_price)^2, 2, mean)\n\nplot(1:n_trees, error_list_train, type=\"l\", col= \"blue\", xlab=\"nTree\", ylab=\"Error\", )\n\nlines(1:n_trees,error_list_test, type=\"l\", col = \"red\")\nlegend(\"topright\", legend = c(\"error_list_train\", \"error_list_test\"), col = c(\"blue\", \"red\"), lty = 1)\n\n#best model\nbest_model <- gbm(log_price ~ ., data = train_data, n.trees = 60, \n                  interaction.depth = 10, shrinkage = 0.1,n.minobsinnode = 5,\n                  distribution = \"gaussian\")\nbest_pred <- predict(best_model, newdata = test_data)\nMSE.gbm = mean((test_data$log_price - best_pred)^2)\n\n\n# calculate var importance\nvar_importance<- summary(model)\n# sort var importance in descending order\nvar_importance_sorted <- var_importance[order(var_importance[,2], decreasing = FALSE),]\nbarplot(var_importance_sorted$rel.inf,\n        names.arg = rownames(var_importance), \n        xlab = \"Score\",\n        main = \"variable importance\",\n        horiz = TRUE,las=1,)\npar(mar = c(3, 12, 2, 4))\n\n\n# # drop  similar variables based on importance\n# train_data2<-subset(train_data, select = -c(hpi_lag3,hpi_1m_pct,hpi_6m_pct,hpi_lag1, HPI))\n# \n# ## best tune\n# gbmgrid<- expand.grid(interaction.depth = c(3,5,7,9), n.trees= c(10,50,100), \n#                       shrinkage =c(0.01, 0.05, 0.1), n.minobsinnode= 5)\n# set.seed(123)\n# \n# gbm_model<- train(log_price~ ., data=na.fill(train_data2,0), method =\"gbm\",\n#                   trControl = trainControl(method =\"cv\", number= 10),\n#                   tuneGrid= gbmgrid)\n# \n# ## best tune\n# gbmgrid2<- expand.grid(interaction.depth = c(9,12), n.trees= c(100, 150), \n#                       shrinkage =c(0.01, 0.05, 0.1), n.minobsinnode= 5)\n# set.seed(123)\n# \n# gbm_model2<- train(log_price~ ., data=na.fill(train_data2,0), method =\"gbm\",\n#                   trControl = trainControl(method =\"cv\", number= 10),\n#                   tuneGrid= gbmgrid2)\n# \n# \n# #best model\n# best_model <- gbm(log_price ~ ., data = train_data, n.trees = 100, \n#              interaction.depth = 9, shrinkage = 0.1,n.minobsinnode = 5,\n#              distribution = \"gaussian\",verbose = TRUE)\n# best_pred <- predict(best_model, newdata = test_data)\n# mse<-mean((test_data$log_price - best_pred)^2)\n# mse\n\n\n\n\n\n\n################################# out of time testing ####################\n# read house data oot\nhouse_data_oot<- read.csv(\"C:\\\\Users\\\\xiaoy\\\\Desktop\\\\UTDS23\\\\6323\\\\project\\\\house_data_oot.csv\")\n\nhouse_data_oot$SOLD_MONTH<- as.Date(\"2023-01-01\")\nhouse_data_oot$base_month<- floor_date(house_data_oot$SOLD_MONTH, unit = \"month\") - months(1)\n\n\n\n# create required variables\n\n\n# merge hpi table with house table\n\nhouse_df_oot<- merge(house_data_oot, hpi,by.x=\"base_month\", by.y=\"DATE\", all.x= TRUE, all.y=FALSE)\nhouse_df_oot$sold_year <- year(as.Date(house_df_oot$SOLD_MONTH))\n\n\n#  house age \nhouse_df_oot$houseage <- house_df_oot$sold_year- house_df_oot$YEARBUILT\n\n#total beds and bath\nhouse_df_oot$total_beds_baths <- house_df_oot$BEDS + house_df_oot$BATHS\n\n#baths and beds ratio\nhouse_df_oot$bath_bed_ratio <- ifelse(house_df_oot$BEDS==0,NA, house_df_oot$BATHS/house_df_oot$BEDS)\n\n#living squarefeet and beds ratio\nhouse_df_oot$sqrt_beds <- ifelse(house_df_oot$BEDS==0, NA, house_df_oot$SQUAREFEET/house_df_oot$BEDS)\n# impute the lotsize outlier to median\nmed_lot<- median(house_df_oot$LOTSIZE, na.rm = TRUE )# we should training median as imputation\nhouse_df_oot$LOTSIZE_imputed <- ifelse(is.na(house_df_oot$LOTSIZE)|house_df_oot$LOTSIZE > 30000|house_df_oot$LOTSIZE< 2000, med_lot,\n                                       house_df_oot$LOTSIZE)\nhouse_df_oot$LOTSIZE_imputed_ind<-ifelse(is.na(house_df_oot$LOTSIZE)|house_df_oot$LOTSIZE > 30000|house_df_oot$LOTSIZE< 2000, 1,0)\n\n#create log lotsize\nhouse_df_oot$log_lotsize <- log(house_df_oot$LOTSIZE_imputed)\n\n\n\n# create new variable age group \n\n#library(dplyr)\nhouse_df_oot <- house_df_oot %>%\n  mutate(age_group = cut(houseage, breaks = c(-0.5,5,10,15,20,25, Inf), labels = c(\"0-5\", \"6-10\", \"11-15\",\"16-20\",\"21-25\",\"25+\"))) \nhouse_df_oot\n\n# create new variable month from sold month \nhouse_df_oot$month_ind<- as.factor(month(house_df_oot$SOLD_MONTH))\n\n#predict oot data on best model\nhouse_df_oot$pred_log_price <- predict(best_model, newdata = house_df_oot)\nhouse_df_oot$pred_price <- exp(house_df_oot$pred_log_price)\n\n\n\npred_error_oot<- ((house_df_oot$pred_price- house_df_oot$PRICE)/ house_df_oot$PRICE)\n\n# stack house data and house oot data \n# drop price from oot data\nhouse_df_oot2<- subset(house_df_oot, select = -c(PRICE))\n\nhouse_df_extended<- bind_rows(house_df,house_df_oot2 )\n\n#median price by month\nprice_med_month_act <- aggregate(PRICE ~ SOLD_MONTH, data=house_df_extended, median)\n\nprice_med_month_pred<- aggregate(pred_price ~ SOLD_MONTH, data=house_df_extended, median)\nprice_med_month <- bind_rows(price_med_month_act,price_med_month_pred )\nprice_med_month$price_all <- ifelse(price_med_month$SOLD_MONTH < \"2023-01-01\" , price_med_month$PRICE, price_med_month$pred_price)\nprice_med_month <- price_med_month%>%\n  mutate(price_all_lag1 = lag(price_all))%>%\n  mutate(price_1m_change =( (price_all/price_all_lag1)-1)*100)\n\npar(mar = c(5, 4, 4, 8))\nplot(price_med_month$SOLD_MONTH, price_med_month$price_all, xlab=\"SOLD_MONTH\", ylab =\"PRICE\",\n     main=\"Median Price by Month\", type= \"l\",xaxt = \"n\",col=\"red\", lty= \"dotted\")  # xaxt = \"n\" removes default x-axis labels\naxis(side = 1, at =  price_med_month$SOLD_MONTH, labels = price_med_month$SOLD_MONTH) \nlines(price_med_month$SOLD_MONTH,price_med_month$PRICE, type=\"l\", col = \"blue\")\npar(new = TRUE)                             # Add new plot\nplot(price_med_month$SOLD_MONTH, price_med_month$price_1m_change,               # Create second plot without axes\n     axes = FALSE, xlab=\"\", ylab = \"\", col=\"green\",type=\"l\")\naxis(side = 4)      # Add second axis\nmtext(\"percentage(%)\", side = 4, line = 3) \n\n\nlegend(\"topleft\", legend = c( \"Predict median price\", \"Actual median price\",\"1 month price change\"), col = c(\"red\", \"blue\",\"green\"), lty = 1)\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"Predicting housing price.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","editor":"visual","theme":"morph"},"extensions":{"book":{"multiFile":true}}}}}