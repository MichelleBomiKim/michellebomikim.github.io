[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Michelle",
    "section": "",
    "text": "I’m currently majoring in SDAR (Socia Data Analytic and Research)"
  },
  {
    "objectID": "Assignment1-1.html",
    "href": "Assignment1-1.html",
    "title": "Michelle Kim",
    "section": "",
    "text": "install.packages(“haven”) library(haven) summary(“TEDS_2016”) TEDS_2016<-read_stata(“https://github.com/datageneration/home/blob/master/DataProgramming/data/TEDS_2016.dta?raw=true”) #There are missing values #How to deal with Missingvalues is.na(“Tondu”) install.packages(“tidyverse”) library(“tidyverse”) install.packages(“dplyr”) Tondu_female <- xtabs(~ Tondu + female, data= TEDS_2016) Tondu_female Tondu_income <- xtabs(~ Tondu + income, data = TEDS_2016 ) Tondu_income Tondu_vontesai <- xtabs(~ Tondu + votetsai, data = TEDS_2016) boxplot(age ~ Tondu, data=TEDS_2016, xlab = “Tondu”, ylab = “age”, main = “Tondu and Age”)\nTEDS_2016\\(Tondu<-as.numeric(TEDS_2016\\)Tondu,labels=c(“Unificationnow”, “Statusquo,unif.infuture”, “Statusquo,decidelater”, “Statusquoforever”, “Statusquo,indep.infuture”, “Independencenow”, “Noresponse”))\nbarplot(table_tondu, main = “Barchart of Tondu”, ylab = “Frequency”, names.arg = c(“unification now”, “Statusquo”, “unif.infuture”, “Statusquoforever”, “Statusquo,indep.infuture”, “Independencenow”, “Noresponse”))"
  },
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "Assignment1",
    "section": "",
    "text": "Google Slides : Yi3RyUCilZo/edit#slide=id.g20320c13c19_0_69XMhRGUqwYD4vrJETNEg1GRok9-hImQj-Yi3RyUCilZo/edit#slide=id.g20320c13c19_0_69"
  },
  {
    "objectID": "Assignment2.html",
    "href": "Assignment2.html",
    "title": "Michelle Kim",
    "section": "",
    "text": "Assignment2\nhttps://docs.google.com/presentation/d/17UuIJb9nWSp0AsZ7pAPO6CxRmOL2ZKJGCQKj4vMByrQ/edit#slide=id.g208bf22879d_0_64"
  },
  {
    "objectID": "assignment4.html#principal-component-analysis",
    "href": "assignment4.html#principal-component-analysis",
    "title": "Michelle Kim",
    "section": "Principal Component Analysis",
    "text": "Principal Component Analysis\nlibrary(datasets) library(ISLR) arrest = USArrests states=row.names(USArrests) names(USArrests) # Get means and variances of variables apply(USArrests, 2, mean) apply(USArrests, 2, var) # PCA with scaling pr.out=prcomp(USArrests, scale=TRUE) names(pr.out) # Five pr.out\\(center # the centering and scaling used (means) pr.out\\)scale # the matrix of variable loadings (eigenvectors) dim(pr.out\\(x) pr.out\\)rotation=-pr.out\\(rotation pr.out\\)x=-pr.out\\(x biplot(pr.out, scale=0) pr.out\\)sdev pr.var=pr.out$sdev^2 pr.var pve=pr.var/sum(pr.var) pve plot(pve, xlab=“Principal Component”, ylab=“Proportion of Variance Explained”, ylim=c(0,1),type=‘b’)\nlibrary(dplyr) library(ggplot2) library(RColorBrewer)\ncomputers = read.csv(“https://raw.githubusercontent.com/guru99-edu/R-Programming/master/computers.csv”)\nrescaled_comp <- computers[4:5] %>% mutate(hd_scal = scale(hd), ram_scal = scale(ram)) %>% select(c(hd_scal, ram_scal))\nggplot(data = rescaled_comp, aes(x = hd_scal, y = ram_scal)) + geom_point(pch=20, col = “blue”) + theme_bw() + labs(x = “Hard drive size (Scaled)”, y =“RAM size (Scaled)” ) + theme(text = element_text(family=“Georgia”))\nlibrary(dplyr) library(ggplot2) library(RColorBrewer)\ncomputers = read.csv(“https://raw.githubusercontent.com/guru99-edu/R-Programming/master/computers.csv”)\nOnly retain two variables for illustration\nrescaled_comp <- computers[4:5] %>% mutate(hd_scal = scale(hd), ram_scal = scale(ram)) %>% select(c(hd_scal, ram_scal))\nggplot(data = rescaled_comp, aes(x = hd_scal, y = ram_scal)) + geom_point(pch=20, col = “blue”) + theme_bw() + labs(x = “Hard drive size (Scaled)”, y =“RAM size (Scaled)” ) + theme(text = element_text(family=“Georgia”))\ninstall.packages(“animation”)\ninstall.packages(“animation”) library(animation) set.seed(2345) library(animation)\nAnimate the K-mean clustering process, cluster no. = 4\nkmeans.ani(rescaled_comp[1:2], centers = 4, pch = 15:18, col = 1:4)"
  },
  {
    "objectID": "Assignment5.html",
    "href": "Assignment5.html",
    "title": "Michelle Kim",
    "section": "",
    "text": "Question2.\n\nQuestion 3.\nWeak Entities are dependent on another entity set. They are associated with an identifying entity. If entity set does not have enough attributes to present uniquely, weak entities provide extra information to identify uniquely.\nQuestion4.\nSelect e.ID,person_name from employee inner join works on e.ID = w.ID inner join company on W.company_name = company.company_name where employee.city = company.city;\n4b) Although the query is syntactically correct, it does not compute the expected answer / dept_name is attribute of both “course” and “instructor. Natural join shows only when instructor teaches a course in her or his own department."
  },
  {
    "objectID": "DMassignment6.html",
    "href": "DMassignment6.html",
    "title": "Michelle Kim",
    "section": "",
    "text": "library(haven) TEDS_2016<-read_stata(“https://github.com/datageneration/home/blob/master/DataProgramming/data/TEDS_2016.dta?raw=true”) data <- “TEDS_2016” summary(data) nrow(data)\nglm.vt=glm(votetsai~edu,data=TEDS_2016,family=binomial) summary(glm.vt)"
  },
  {
    "objectID": "Earthquakedata.html",
    "href": "Earthquakedata.html",
    "title": "Michelle Kim",
    "section": "",
    "text": "Earthquake<- query_1_ Earthquake2<- newdata<- subset(Earthquake, select = c(latitude, mag, longitude, time, place, depth))"
  },
  {
    "objectID": "EPPS6323.html",
    "href": "EPPS6323.html",
    "title": "Michelle Kim",
    "section": "",
    "text": "Readings\nDMC- data modeling culture, encourage to pursue ever deeper knowledge production.\nDescription- statistical inference about aspects of distribution of one or more events.\nCausal system events relationship between events in a domain of interest."
  },
  {
    "objectID": "example.html",
    "href": "example.html",
    "title": "example",
    "section": "",
    "text": "This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00"
  },
  {
    "objectID": "example.html#including-plots",
    "href": "example.html#including-plots",
    "title": "example",
    "section": "Including Plots",
    "text": "Including Plots\nYou can also embed plots, for example:\nlibrary(shiny)\nui <- basicPage( plotOutput(“plot1”, click = “plot_click”), verbatimTextOutput(“info”) )\nserver <- function(input, output) { output\\(plot1 <- renderPlot({  plot(mtcars\\)wt, mtcars$mpg) })\noutput\\(info <- renderText({  paste0(\"x=\", input\\)plot_click\\(x, \"\\ny=\", input\\)plot_click$y) }) }\nshinyApp(ui, server)\nNote that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Michellebomikim",
    "section": "",
    "text": "This is a Michelle Kim’s website. Most of my assignments can be find here! I’m currently enrolled in Data Visualization and Data Methods."
  },
  {
    "objectID": "lab3.html",
    "href": "lab3.html",
    "title": "Michelle Kim",
    "section": "",
    "text": "library(haven) library(regplot) TEDS_2016 <- read_stata(“https://github.com/datageneration/home/blob/master/DataProgramming/data/TEDS_2016.dta?raw=true”) summary(TEDS_2016) TEDS_2016\\(Tondu <-as.numeric(TEDS_2016\\)Tondu,labels=c(“Unification now”, “Status quo, unif. in future”, “Status quo, decide later”, “Status quo forever”, “Status quo, indep. in future”, “Independence now”, “No response”)) df1 <- TEDS_2016[,c(“Tondu”, “age”,“edu”,“income”)] reg <- lm (Tondu~ age+ edu + income, data=df1) summary(reg) regplot(reg)"
  },
  {
    "objectID": "PPTproposal.html",
    "href": "PPTproposal.html",
    "title": "Michelle Kim",
    "section": "",
    "text": "https://docs.google.com/presentation/d/1aojfTLAhsshz88oTHppkk8XJ3_kiANNtXNWO-Uz_ugQ/edit?usp=sharing"
  },
  {
    "objectID": "Predicting housing price.html",
    "href": "Predicting housing price.html",
    "title": "Michelle Kim",
    "section": "",
    "text": "library(“dplyr”) newdata <- X6323data_2_[c(‘BATHS’, ‘BEDS’, ‘ZIP’)] count(newdata) table(newdata\\(BATHS) BATHSFREQ <-table(newdata\\)BATHS) BATHSFREQ freq_ZIP<- table(newdata\\(ZIP) freq_ZIP freq_table <- table(newdata\\)BATHS) freq_table freq_table2 <- table(newdata$BEDS) freq_table2 library(“dplyr”) count(newdata, c(‘ZIP’, ‘BEDS’, ‘BATHS’)) library(dplyr) f<- newdata %>% count(ZIP, BEDS, BATHS) f model_data <- subset(X6323data_2_, select = c(“PRICE”, “BEDS”, “BATHS”)) model_data2 <- na.omit(model_data) library(ggplot2) data_no_zero <- subset(model_data2, PRICE != 0) sum(is.na(data_no_zero)) ggplot(model_data2, aes(x = “BEDS”, y = “Price”)) + geom_point() data_no_zero <- na.omit(model_data) data_no_zero <- subset(X6323data_2_, select = c(“PRICE”, “BEDS”, “BATHS”)) data_no_zero <- na.omit(model_data) x_matrix <- model.matrix(~ BEDS + BATHS, data = model_data2) b <-lm(PRICE~BEDS , data = data_no_zero)\nlibrary(ggplot2) model_data <- subset(X6323data_2_, select = c(“PRICE”, “BEDS”, “BATHS”)) model_data2 <- na.omit(model_data) data_no_zero <- subset(model_data2, PRICE != 0) sum(is.na(data_no_zero)) ggplot(data_no_zero, aes(x = BEDS, y = PRICE)) + geom_point() x_matrix <- model.matrix(~ BEDS + BATHS, data = data_no_zero) b <- lm(PRICE ~ BEDS + BATHS, data = data_no_zero) summary(b)\nlibrary(ggplot2) library(dplyr) library(lubridate) ################ input data ############# #read house data house_data<- read.csv(“C:\\Users\\xiaoy\\Desktop\\UTD S23\\6323\\project\\house_data.csv”)"
  },
  {
    "objectID": "Predicting housing price.html#create-new-variables-of-house-data",
    "href": "Predicting housing price.html#create-new-variables-of-house-data",
    "title": "Michelle Kim",
    "section": "create new variables of house data",
    "text": "create new variables of house data"
  },
  {
    "objectID": "Predicting housing price.html#variable-transformation",
    "href": "Predicting housing price.html#variable-transformation",
    "title": "Michelle Kim",
    "section": "variable transformation",
    "text": "variable transformation\n#log transformation for house price, lotsize, squarefeet\nhist(house_df\\(PRICE) hist(log(house_df\\)PRICE)) house_df\\(log_price <- log(house_df\\)PRICE)\nhist(house_df\\(SQUAREFEET) hist(log(house_df\\)SQUAREFEET)) # log sqrt is skewed to the left, original is better\nhist(house_df\\(LOTSIZE_imputed) hist(log(house_df\\)LOTSIZE_imputed)) house_df\\(log_lotsize <- log(house_df\\)LOTSIZE_imputed) hist(house_df\\(BEDS) hist(house_df\\)BATHS)\n\ndata analysis"
  },
  {
    "objectID": "Predicting housing price.html#cross-table",
    "href": "Predicting housing price.html#cross-table",
    "title": "Michelle Kim",
    "section": "cross table",
    "text": "cross table"
  }
]